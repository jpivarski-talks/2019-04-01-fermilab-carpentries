{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## uproot overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Uproot is a pure Python + Numpy reader of ROOT files.\n",
    "\n",
    "   * Without a C++ layer, there are no memory ownership issues between C++ and Python.\n",
    "   * Different design: instead of delivering event objects, uproot delivers columns of data as (jagged) arrays.\n",
    "   * Not hampered by slow Python execution because data in ROOT files are laid out as (jagged) arrays: just need to cast them as Numpy arrays.\n",
    "\n",
    "_(Disclosure: I'm the author of uproot.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In uproot, files, directories within files, and TTrees/TBranches behave like Python dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "file = uproot.open(\"http://scikit-hep.org/uproot/examples/Event.root\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"ProcessID0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"htime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = file[\"T\"]\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.keys()   # allkeys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get a sense of what a TTree contains, use `show`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To read a (jagged) array, call `array` or `arrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fTracks.fMass2\"].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.array(\"fTracks.fMass2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.arrays([\"fTracks.fMass2\", \"fTracks.fCharge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretations\n",
    "\n",
    "The translation from ROOT data to an array is given by the branch's `interpretation` (if it has one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fNtrack\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fTemperature\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fMatrix[4][4]\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fTracks.fMass2\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fTracks.fCharge\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fH\"].interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If a branch has no `interpretation`, it can't be read. Either it's a no-data branch (exists just for structure) or it's an instance of uproot's incompleteness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree[\"fTracks.fPointValue\"].interpretation)   # as of April 2019, this one has no interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bytes can be read and even divided along entry boundaries, but we don't yet know how to turn the bytes into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uproot.asdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fTracks.fPointValue\"].array(uproot.asdebug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Complex classes are generated based on the ROOT file's self-describing streamers, but they aren't necessarily fast to read (more Python than Numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fH\"].interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = tree[\"fH\"].array()\n",
    "histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting into memory constraints\n",
    "\n",
    "Restricting the range of entries avoids reading too many baskets (chunks on disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.numentries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fMatrix[4][4]\"].numbaskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"fMatrix[4][4]\"].array(entrystart=600, entrystop=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Typically, you'd want to read chunk of entries from all interesting branches, do some work, then move on to the next chunk: use `iterate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "for arrays in tree.iterate([\"fTracks.fPx\", \"fTracks.fPy\"], entrysteps=300):\n",
    "    mag = numpy.sqrt(arrays[b\"fTracks.fPx\"]**2 + arrays[b\"fTracks.fPy\"]**2)\n",
    "    print(len(mag), mag[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The same for a set of files is `uproot.iterate` (supply file names with wildcards and tree name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no wildcards for XRootD and HTTP\n",
    "filenames = [\"http://scikit-hep.org/uproot/examples/HZZ\" + x + \".root\" for x in [\"\", \"-zlib\", \"-lz4\", \"-lzma\"]]\n",
    "for arrays in uproot.iterate(filenames, \"events\", [\"Muon_Px\", \"Muon_Py\"]):\n",
    "    mag = numpy.sqrt(arrays[b\"Muon_Px\"]**2 + arrays[b\"Muon_Py\"]**2)\n",
    "    print(len(mag), mag[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encodings, outputtypes, and Pandas\n",
    "\n",
    "In the previous examples, `tree.arrays` returns a dict of arrays. Branch names have no encoding, so the keys of these dicts are bytestrings (a little annoying in Python 3). Here are some things you can do about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = tree.arrays([\"fTracks.fPx\", \"fTracks.fPy\"], namedecode=\"utf-8\")\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "px, py = tree.arrays([\"fTracks.fPx\", \"fTracks.fPy\"], outputtype=tuple)\n",
    "print(px)\n",
    "print(py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "arrays = tree.arrays([\"fNtrack\", \"fNseg\", \"fNvertex\"], outputtype=collections.namedtuple)\n",
    "print(arrays.fNtrack[:5], arrays.fNseg[:5], arrays.fNvertex[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "tree.arrays([\"fTracks.fP*\"], outputtype=pandas.DataFrame)   # , flatten=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you're outputting to Pandas, you probably want to `namedecode` and `flatten`, so there are `tree.pandas.df`, `tree.pandas.iterate` methods and an `uproot.pandas.iterate` function for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = \"http://scikit-hep.org/uproot/examples/HZZ.root\"\n",
    "for df in uproot.pandas.iterate(filenames, \"events\", [\"MET_p*\", \"Muon_P*\"], entrysteps=1000):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caching\n",
    "\n",
    "Uproot does not cache the arrays that you read (except raw data in HTTP and XRootD transfers). If you pass through the same data more than once, it might pay to cache it.\n",
    "\n",
    "Any dict-like object may be used as a cache. Simplest case: a real dict (keep forever cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "tree.arrays(\"fH\", cache=cache)\n",
    "list(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.arrays(\"fH\", cache=cache)   # gets it from the dict, not the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To put an upper limit on memory use, use an `ArrayCache` (which evicts the least recently accessed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = uproot.cache.ArrayCache(limitbytes=1024**3)   # 1 GB\n",
    "tree.arrays(\"fH\", cache=cache)\n",
    "list(cache.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel processing\n",
    "\n",
    "In rare cases (e.g. dominated by LZMA decompression), it can be advantageous to read the data in parallel. If you're dominated by processing, just split up your job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "executor = ThreadPoolExecutor(4)    # split work into 4 threads\n",
    "\n",
    "arrays = tree.arrays([\"fTracks.fP*\"], executor=executor, blocking=False)\n",
    "arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The optional `blocking=False` argument means \"return a `wait` function.\" Reading and decompressing continue while you do other things; calling the function returns the result, waiting if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lazy evaluation\n",
    "\n",
    "Another common pattern is lazy evaluation: get an array-like object and only read/decompress when you access it. If you supply an `ArrayCache`, you can also limit its memory use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = tree.lazyarrays([\"fTracks.fP*\"], namedecode=\"utf-8\")\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arrays[\"fTracks.fPx\"][:10]   # now it reads from the first basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays[\"fTracks.fPx\"][-10:]   # now it reads from the last basket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dask (parallel processing)\n",
    "\n",
    "Dask is a parallel processing framework based on lazy evaluation. Similar functions produce Dask arrays and Dask DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = \"http://scikit-hep.org/uproot/examples/HZZ.root\"\n",
    "arrays = uproot.daskarrays(filenames, \"events\", [\"MET_p*\", \"Muon_P*\"])\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = uproot.daskframe(filenames, \"events\", [\"MET_p*\", \"Muon_P*\"])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
